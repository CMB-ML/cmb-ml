{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Your Local System\n",
    "\n",
    "We now need to set up your local system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the local_system configuration file\n",
    "\n",
    "First you'll create a configuration file.\n",
    "\n",
    "I suggest using [mine](../cfg/local_system/generic_lab.yaml) as an example. Open that file and take a look. It has two keys.\n",
    "\n",
    "The `datasets_root` will be where the datasets themselves are written. At first this will contain, for a dataset, only the simulation and the Logs generated while producing that simulation. As more of the pipeline is run, many stages will create folders alongside simulation.\n",
    "\n",
    "The `assets_dir` is only for the science assets (maps used for noise, instrument parameters, cosmological parameter distributions). It is used once.\n",
    "\n",
    "Set those according to your local system.\n",
    "\n",
    "If more granularity of file storage is needed (e.g., you want to store models on a faster drive or analysis results on a slower drive), this can also be done in the pipeline yamls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the top level configuration file\n",
    "\n",
    "We also need to let your system know where that yaml is. This information goes in top level configurations, e.g. [config_setup.yaml](../cfg/config_setup.yaml), which look like:\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - local_system: ${oc.env:CMB_ML_LOCAL_SYSTEM}\n",
    "  - file_system : common_fs\n",
    "  - override hydra/job_logging: custom_log\n",
    "  - _self_\n",
    "```\n",
    "\n",
    "For `local_system`, either change the value to the name of your local system yaml file, e.g.:\n",
    "\n",
    "```yaml\n",
    "  - local_system: generic_lab.yaml\n",
    "```\n",
    "\n",
    "Or add an environment variable to your system. On linux working with Python scripts, the command `export CMB_ML_LOCAL_SYSTEM=generic_lab.yaml` would be added to your shell startup script. In jupyter notebooks, this is done through the `os` library. This option is very useful for researchers using the dataset on multiple systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the configuration\n",
    "\n",
    "Set this up now for both your local system configuration and [config_setup.yaml](../cfg/config_setup.yaml). Let's see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Set the environment variable, only effective for this notebook.\n",
    "os.environ['CMB_ML_LOCAL_SYSTEM'] = 'generic_lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_system:\n",
      "  datasets_root: /data/generic_user/CMB_Data/Datasets/\n",
      "  assets_dir: /data/generic_user/CMB_Data/Assets/\n",
      "file_system:\n",
      "  sim_folder_prefix: sim\n",
      "  sim_str_num_digits: 4\n",
      "  dataset_template_str: '{root}/{dataset}/'\n",
      "  default_dataset_template_str: '{root}/{dataset}/{stage}/{split}/{sim}'\n",
      "  working_dataset_template_str: '{root}/{dataset}/{working}{stage}/{split}/{sim}'\n",
      "  subdir_for_log_scripts: scripts\n",
      "  log_dataset_template_str: '{root}/{dataset}/{hydra_run_dir}'\n",
      "  log_stage_template_str: '{root}/{dataset}/{working}{stage}/{hydra_run_dir}'\n",
      "  top_level_work_template_str: '{root}/{dataset}/{stage}/{hydra_run_dir}'\n",
      "  wmap_chains_dir: WMAP/wmap_lcdm_mnu_wmap9_chains_v5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The following line is simply in case you run this cell twice.\n",
    "# This will clear the global hydra instance.\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "# Get hydra ready\n",
    "initialize(version_base=None, config_path=\"../cfg\")\n",
    "\n",
    "# Load the config\n",
    "cfg = compose(config_name='config_setup.yaml')\n",
    "\n",
    "# Print the config\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those look good to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up PyILC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've solved this in a way that may not be ideal. Feedback is welcomed.\n",
    "\n",
    "PyILC isn't structured as an installable library. I've settled on a workaround of importing the necessary elements in a CMB-ML module. This allows the use of PyILC without any modification of PyILC code, and without unnecessary duplication of effort.\n",
    "\n",
    "First, you'll need to get the code (those comfortable with all this should feel free to skip this paragraph). I don't recommend adding one git-tracked repository inside another. For instance, if you have '/home/a_bunch_of_repos/cmb-ml/', `cd /home/a_bunch_of_repos`. Clone PyILC at this location, using `git clone https://github.com/jcolinhill/pyilc.git` (or some equivalent).\n",
    "\n",
    "Next, within the CMB-ML repository, open (cmbml/pyilc_redir/__init__.py)[./cmbml/pyilc_redir/__init__.py]. Edit the path to match the location where you've installed PyILC, specifically `input.py` and `wavelets.py`.\n",
    "\n",
    "It should look like:\n",
    "```\n",
    "import sys\n",
    "sys.path.append('/absolute/path/to/pyilc/pyilc')\n",
    "\n",
    "from input import ILCInfo\n",
    "from wavelets import Wavelets, wavelet_ILC, harmonic_ILC\n",
    "```\n",
    "\n",
    "Voila! I do not recommend this practice in general as it may cause security vulnerabilities or other terrible things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Science Assets\n",
    "\n",
    "<!-- We now need to get either:\n",
    "- All science assets for running simulations\n",
    "- Just the asset containing the mask used for analysis -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Science Assets\n",
    "\n",
    "The easiest method is the simplest: run [the get_data/get_assets.py](../get_data/get_assets.py) script. This will download from the ESA's Planck Legacy Archive and from NASA's LAMBDA Archive.\n",
    "\n",
    "Downloads may be slow. There is also a CMB-ML data mirror for these files, but links are not currently available. Please contact us through the GitHub repository for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing\n",
    "\n",
    "Your system is now set up to use CMB-ML.\n",
    "\n",
    "Next, we'll look at a couple simulations to better understand the data, in [the next demonstration notebook](./D_getting_dataset_instances.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmbml_namaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
